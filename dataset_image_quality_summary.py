#!/usr/bin/env python3
"""
Dataset Image Quality Summary
Analyzes and summarizes image quality metrics from CSV files generated by image_quality_grader.py
"""

import pandas as pd
import numpy as np
from pathlib import Path
import csv_excel_converter

# Metric configurations
# 'lower_is_better' means lower values indicate better quality (distortion metrics)
# 'higher_is_better' means higher values indicate better quality (quality metrics)
METRICS_CONFIG = {
    'niqe': {'type': 'lower_is_better', 'group': 'traditional'},
    'brisque': {'type': 'lower_is_better', 'group': 'traditional'},
    'piqe': {'type': 'lower_is_better', 'group': 'traditional'},
    'musiq': {'type': 'higher_is_better', 'group': 'modern'},
    'clipiqa': {'type': 'higher_is_better', 'group': 'modern'}
}

def get_available_csv_files(folder_path):
    """Get all CSV files in the specified folder"""
    folder = Path(folder_path)
    if not folder.exists():
        return []
    
    csv_files = sorted([f for f in folder.glob('*.csv')])
    return csv_files

def select_csv_files(csv_files):
    """Let user select which CSV files to analyze"""
    print("\nAvailable CSV files:")
    for i, file in enumerate(csv_files, 1):
        print(f"  {i}. {file.name}")
    
    print("\nSelection options:")
    print("  • Enter numbers separated by commas (e.g., 1,3,5)")
    print("  • Enter 'all' to select all files")
    print("  • Press Enter to select all files")
    
    while True:
        try:
            user_input = input("\nSelect CSV files to analyze: ").strip()
            
            if not user_input or user_input.lower() == 'all':
                return csv_files
            
            # Parse comma-separated numbers
            selected_indices = []
            for num_str in user_input.split(','):
                num_str = num_str.strip()
                if num_str:
                    idx = int(num_str) - 1
                    if 0 <= idx < len(csv_files):
                        selected_indices.append(idx)
                    else:
                        print(f"ERROR: Invalid number: {num_str}. Please use numbers 1-{len(csv_files)}")
                        break
            else:
                if selected_indices:
                    return [csv_files[i] for i in selected_indices]
                print("ERROR: Please enter valid file numbers.")
            
        except ValueError:
            print("ERROR: Please enter valid numbers separated by commas.")
        except KeyboardInterrupt:
            print("\nOperation cancelled.")
            return None

def load_quality_data(csv_file):
    """Load quality metrics from a CSV file"""
    try:
        df = pd.read_csv(csv_file)
        
        # Verify required columns exist
        required_metrics = list(METRICS_CONFIG.keys())
        missing_metrics = [m for m in required_metrics if m not in df.columns]
        
        if missing_metrics:
            print(f"WARNING: {csv_file.name} is missing metrics: {missing_metrics}")
            return None
        
        return df
    except Exception as e:
        print(f"ERROR: Failed to load {csv_file.name}: {e}")
        return None

def calculate_statistics(values):
    """Calculate comprehensive statistics for a series of values"""
    values = pd.Series(values).dropna()
    
    if len(values) == 0:
        return {
            'mean': np.nan,
            'median': np.nan,
            'std': np.nan,
            'min': np.nan,
            'max': np.nan,
            'count': 0
        }
    
    return {
        'mean': values.mean(),
        'median': values.median(),
        'std': values.std(),
        'min': values.min(),
        'max': values.max(),
        'count': len(values)
    }

def normalize_metric(values, metric_name, global_min=None, global_max=None):
    """
    Normalize metric values to 0-100 scale where 100 = best quality
    
    Args:
        values: Array of metric values
        metric_name: Name of the metric
        global_min: Global minimum for normalization (if None, use local min)
        global_max: Global maximum for normalization (if None, use local max)
    
    Returns:
        Normalized values (0-100 scale)
    """
    values = np.array(values)
    
    # Use global or local min/max
    min_val = global_min if global_min is not None else np.min(values)
    max_val = global_max if global_max is not None else np.max(values)
    
    # Avoid division by zero
    if max_val == min_val:
        return np.full_like(values, 50.0, dtype=float)
    
    # Normalize to 0-100
    metric_type = METRICS_CONFIG[metric_name]['type']
    
    if metric_type == 'lower_is_better':
        # For distortion metrics: lower is better, so invert
        normalized = 100.0 * (max_val - values) / (max_val - min_val)
    else:
        # For quality metrics: higher is better
        normalized = 100.0 * (values - min_val) / (max_val - min_val)
    
    return normalized

def analyze_single_file(csv_file, global_stats=None, selected_metrics=None, selected_stats=None, include_combined=None):
    """Analyze quality metrics for a single CSV file"""
    df = load_quality_data(csv_file)
    if df is None:
        return None
    
    # Default to all metrics and stats if not specified
    if selected_metrics is None:
        selected_metrics = list(METRICS_CONFIG.keys())
    if selected_stats is None:
        selected_stats = ['mean', 'median', 'std', 'min', 'max']
    if include_combined is None:
        include_combined = {'traditional': True, 'modern': True, 'overall': True}
    
    results = {
        'filename': csv_file.name,
        'total_images': len(df)
    }
    
    # Calculate statistics for each metric
    for metric_name in METRICS_CONFIG.keys():
        if metric_name in df.columns and metric_name in selected_metrics:
            stats = calculate_statistics(df[metric_name])
            
            # Store raw statistics (exclude count, only selected stats)
            for stat_name, stat_value in stats.items():
                if stat_name != 'count' and stat_name in selected_stats:
                    results[f'{metric_name}_{stat_name}'] = stat_value
    
    # Calculate normalized and combined metrics (only if requested)
    if global_stats is not None and any(include_combined.values()):
        # Use global min/max for normalization
        normalized_metrics = {}
        
        for metric_name in METRICS_CONFIG.keys():
            if metric_name in df.columns:
                global_min = global_stats[metric_name]['min']
                global_max = global_stats[metric_name]['max']
                normalized = normalize_metric(df[metric_name], metric_name, global_min, global_max)
                normalized_metrics[metric_name] = normalized
        
        # Calculate combined averages (only if requested)
        if include_combined['traditional'] and all(m in normalized_metrics for m in ['niqe', 'brisque', 'piqe']):
            traditional_combined = np.mean([
                normalized_metrics['niqe'],
                normalized_metrics['brisque'],
                normalized_metrics['piqe']
            ], axis=0)
            results['traditional_combined_mean'] = np.mean(traditional_combined)
            results['traditional_combined_median'] = np.median(traditional_combined)
            results['traditional_combined_std'] = np.std(traditional_combined)
        
        if include_combined['modern'] and all(m in normalized_metrics for m in ['musiq', 'clipiqa']):
            modern_combined = np.mean([
                normalized_metrics['musiq'],
                normalized_metrics['clipiqa']
            ], axis=0)
            results['modern_combined_mean'] = np.mean(modern_combined)
            results['modern_combined_median'] = np.median(modern_combined)
            results['modern_combined_std'] = np.std(modern_combined)
        
        if include_combined['overall'] and len(normalized_metrics) == 5:
            all_combined = np.mean(list(normalized_metrics.values()), axis=0)
            results['overall_combined_mean'] = np.mean(all_combined)
            results['overall_combined_median'] = np.median(all_combined)
            results['overall_combined_std'] = np.std(all_combined)
    
    return results

def calculate_global_stats(selected_files):
    """Calculate global min/max for all metrics across all selected files"""
    global_stats = {metric: {'min': float('inf'), 'max': float('-inf')} 
                    for metric in METRICS_CONFIG.keys()}
    
    print("\nCalculating global statistics across all selected files...")
    
    for csv_file in selected_files:
        df = load_quality_data(csv_file)
        if df is None:
            continue
        
        for metric_name in METRICS_CONFIG.keys():
            if metric_name in df.columns:
                values = df[metric_name].dropna()
                if len(values) > 0:
                    global_stats[metric_name]['min'] = min(global_stats[metric_name]['min'], values.min())
                    global_stats[metric_name]['max'] = max(global_stats[metric_name]['max'], values.max())
    
    return global_stats

def analyze_overall(selected_files, global_stats, selected_metrics=None, selected_stats=None, include_combined=None):
    """Analyze quality metrics across all selected files combined"""
    print("\nCombining data from all selected files...")
    
    # Default to all metrics and stats if not specified
    if selected_metrics is None:
        selected_metrics = list(METRICS_CONFIG.keys())
    if selected_stats is None:
        selected_stats = ['mean', 'median', 'std', 'min', 'max']
    if include_combined is None:
        include_combined = {'traditional': True, 'modern': True, 'overall': True}
    
    # Combine all dataframes
    all_dfs = []
    for csv_file in selected_files:
        df = load_quality_data(csv_file)
        if df is not None:
            all_dfs.append(df)
    
    if not all_dfs:
        return None
    
    combined_df = pd.concat(all_dfs, ignore_index=True)
    
    results = {
        'filename': 'OVERALL_COMBINED',
        'total_images': len(combined_df)
    }
    
    # Calculate statistics for each metric
    for metric_name in METRICS_CONFIG.keys():
        if metric_name in combined_df.columns and metric_name in selected_metrics:
            stats = calculate_statistics(combined_df[metric_name])
            
            # Store raw statistics (exclude count, only selected stats)
            for stat_name, stat_value in stats.items():
                if stat_name != 'count' and stat_name in selected_stats:
                    results[f'{metric_name}_{stat_name}'] = stat_value
    
    # Calculate normalized and combined metrics
    normalized_metrics = {}
    
    for metric_name in METRICS_CONFIG.keys():
        if metric_name in combined_df.columns:
            global_min = global_stats[metric_name]['min']
            global_max = global_stats[metric_name]['max']
            normalized = normalize_metric(combined_df[metric_name], metric_name, global_min, global_max)
            normalized_metrics[metric_name] = normalized
    
    # Calculate combined averages (only if requested)
    if include_combined['traditional'] and all(m in normalized_metrics for m in ['niqe', 'brisque', 'piqe']):
        traditional_combined = np.mean([
            normalized_metrics['niqe'],
            normalized_metrics['brisque'],
            normalized_metrics['piqe']
        ], axis=0)
        results['traditional_combined_mean'] = np.mean(traditional_combined)
        results['traditional_combined_median'] = np.median(traditional_combined)
        results['traditional_combined_std'] = np.std(traditional_combined)
    
    if include_combined['modern'] and all(m in normalized_metrics for m in ['musiq', 'clipiqa']):
        modern_combined = np.mean([
            normalized_metrics['musiq'],
            normalized_metrics['clipiqa']
        ], axis=0)
        results['modern_combined_mean'] = np.mean(modern_combined)
        results['modern_combined_median'] = np.median(modern_combined)
        results['modern_combined_std'] = np.std(modern_combined)
    
    if include_combined['overall'] and len(normalized_metrics) == 5:
        all_combined = np.mean(list(normalized_metrics.values()), axis=0)
        results['overall_combined_mean'] = np.mean(all_combined)
        results['overall_combined_median'] = np.median(all_combined)
        results['overall_combined_std'] = np.std(all_combined)
    
    return results

def save_results_to_csv(results_list, output_file):
    """Save analysis results to CSV file"""
    try:
        df = pd.DataFrame(results_list)
        df.to_csv(output_file, index=False)
        print(f"\nSUCCESS: Report saved to: {output_file}")
        return True
    except Exception as e:
        print(f"\nERROR: Failed to save report: {e}")
        return False

def select_metrics_and_stats():
    """Let user select which metrics and statistics to include"""
    print("\n" + "=" * 80)
    print("SELECT METRICS TO ANALYZE")
    print("=" * 80)
    
    # Metric selection
    print("\nAvailable metrics:")
    metrics_list = list(METRICS_CONFIG.keys())
    for i, metric in enumerate(metrics_list, 1):
        metric_type = METRICS_CONFIG[metric]['type']
        type_desc = "lower=better" if metric_type == 'lower_is_better' else "higher=better"
        print(f"  {i}. {metric.upper():<10} ({type_desc})")
    
    print("\nSelection options:")
    print("  • Enter numbers separated by commas (e.g., 1,3,5)")
    print("  • Enter 'all' or press Enter to select all metrics")
    
    selected_metrics = []
    while True:
        try:
            user_input = input("\nSelect metrics to include: ").strip()
            
            if not user_input or user_input.lower() == 'all':
                selected_metrics = metrics_list
                break
            
            # Parse comma-separated numbers
            for num_str in user_input.split(','):
                num_str = num_str.strip()
                if num_str:
                    idx = int(num_str) - 1
                    if 0 <= idx < len(metrics_list):
                        if metrics_list[idx] not in selected_metrics:
                            selected_metrics.append(metrics_list[idx])
                    else:
                        print(f"ERROR: Invalid number: {num_str}. Please use numbers 1-{len(metrics_list)}")
                        break
            else:
                if selected_metrics:
                    break
                print("ERROR: Please select at least one metric.")
        except ValueError:
            print("ERROR: Please enter valid numbers separated by commas.")
    
    # Statistics selection
    print("\n" + "=" * 80)
    print("SELECT STATISTICS TO INCLUDE")
    print("=" * 80)
    
    print("\nAvailable statistics:")
    stats_list = ['mean', 'median', 'std', 'min', 'max']
    stats_descriptions = {
        'mean': 'Average value',
        'median': 'Middle value',
        'std': 'Standard deviation (variability)',
        'min': 'Minimum value',
        'max': 'Maximum value'
    }
    for i, stat in enumerate(stats_list, 1):
        print(f"  {i}. {stat.upper():<10} - {stats_descriptions[stat]}")
    
    print("\nSelection options:")
    print("  • Enter numbers separated by commas (e.g., 1,2,3)")
    print("  • Enter 'all' or press Enter to select all statistics")
    
    selected_stats = []
    while True:
        try:
            user_input = input("\nSelect statistics to include: ").strip()
            
            if not user_input or user_input.lower() == 'all':
                selected_stats = stats_list
                break
            
            # Parse comma-separated numbers
            for num_str in user_input.split(','):
                num_str = num_str.strip()
                if num_str:
                    idx = int(num_str) - 1
                    if 0 <= idx < len(stats_list):
                        if stats_list[idx] not in selected_stats:
                            selected_stats.append(stats_list[idx])
                    else:
                        print(f"ERROR: Invalid number: {num_str}. Please use numbers 1-{len(stats_list)}")
                        break
            else:
                if selected_stats:
                    break
                print("ERROR: Please select at least one statistic.")
        except ValueError:
            print("ERROR: Please enter valid numbers separated by commas.")
    
    # Combined metrics selection
    print("\n" + "=" * 80)
    print("INCLUDE COMBINED METRICS?")
    print("=" * 80)
    
    print("\nCombined metrics options:")
    print("  1. Traditional combined (NIQE + BRISQUE + PIQE) - normalized")
    print("  2. Modern combined (MUSIQ + CLIPIQA) - normalized")
    print("  3. Overall combined (all metrics) - normalized")
    
    print("\nSelection options:")
    print("  • Enter numbers separated by commas (e.g., 1,3)")
    print("  • Enter 'all' to include all combined metrics")
    print("  • Enter 'none' or press Enter to skip combined metrics")
    
    include_combined = {
        'traditional': False,
        'modern': False,
        'overall': False
    }
    
    user_input = input("\nSelect combined metrics: ").strip()
    
    if user_input.lower() == 'all':
        include_combined = {'traditional': True, 'modern': True, 'overall': True}
    elif user_input and user_input.lower() != 'none':
        try:
            for num_str in user_input.split(','):
                num_str = num_str.strip()
                if num_str:
                    choice = int(num_str)
                    if choice == 1:
                        include_combined['traditional'] = True
                    elif choice == 2:
                        include_combined['modern'] = True
                    elif choice == 3:
                        include_combined['overall'] = True
        except ValueError:
            print("WARNING: Invalid input. Skipping combined metrics.")
    
    print(f"\nSelected: {len(selected_metrics)} metric(s), {len(selected_stats)} statistic(s)")
    
    return selected_metrics, selected_stats, include_combined

def display_summary(results_list, selected_metrics=None, selected_stats=None, include_combined=None):
    """Display a summary of the results in console"""
    if selected_metrics is None:
        selected_metrics = list(METRICS_CONFIG.keys())
    if selected_stats is None:
        selected_stats = ['mean', 'median', 'std', 'min', 'max']
    if include_combined is None:
        include_combined = {'traditional': True, 'modern': True, 'overall': True}
    
    print("\n" + "=" * 100)
    print("IMAGE QUALITY SUMMARY")
    print("=" * 100)
    
    for result in results_list:
        print(f"\n{'─' * 100}")
        print(f"File: {result['filename']}")
        print(f"Total Images: {result['total_images']}")
        print(f"{'─' * 100}")
        
        # Individual metrics
        if selected_metrics:
            print("\nINDIVIDUAL METRICS (Raw Values):")
            
            # Build header dynamically based on selected stats
            header = f"{'Metric':<12}"
            for stat in selected_stats:
                header += f" {stat.capitalize():<12}"
            print(header)
            print("─" * (12 + 13 * len(selected_stats)))
            
            for metric_name in selected_metrics:
                # Check if at least one stat exists for this metric
                has_data = any(f'{metric_name}_{stat}' in result for stat in selected_stats)
                if has_data:
                    row = f"{metric_name:<12}"
                    for stat in selected_stats:
                        key = f'{metric_name}_{stat}'
                        if key in result:
                            row += f" {result[key]:<12.4f}"
                        else:
                            row += f" {'N/A':<12}"
                    print(row)
        
        # Combined metrics (normalized)
        show_combined = any(include_combined.values())
        if show_combined and ('traditional_combined_mean' in result or 'modern_combined_mean' in result or 'overall_combined_mean' in result):
            print("\nCOMBINED METRICS (Normalized 0-100, where 100 = best quality):")
            print(f"{'Metric Group':<30} {'Mean':<12} {'Median':<12} {'Std Dev':<12}")
            print("─" * 66)
            
            if include_combined['traditional'] and 'traditional_combined_mean' in result:
                print(f"{'Traditional (NIQE+BRISQUE+PIQE)':<30} "
                      f"{result['traditional_combined_mean']:<12.2f} "
                      f"{result['traditional_combined_median']:<12.2f} "
                      f"{result['traditional_combined_std']:<12.2f}")
            
            if include_combined['modern'] and 'modern_combined_mean' in result:
                print(f"{'Modern (MUSIQ+CLIPIQA)':<30} "
                      f"{result['modern_combined_mean']:<12.2f} "
                      f"{result['modern_combined_median']:<12.2f} "
                      f"{result['modern_combined_std']:<12.2f}")
            
            if include_combined['overall'] and 'overall_combined_mean' in result:
                print(f"{'Overall (All Metrics)':<30} "
                      f"{result['overall_combined_mean']:<12.2f} "
                      f"{result['overall_combined_median']:<12.2f} "
                      f"{result['overall_combined_std']:<12.2f}")

def main():
    print("=" * 100)
    print("DATASET IMAGE QUALITY SUMMARY ANALYZER")
    print("=" * 100)
    
    # Get folder containing CSV files
    while True:
        folder_input = input("\nEnter folder path containing quality report CSV files: ").strip().strip('"').strip("'")
        if not folder_input:
            print("ERROR: No folder path provided")
            return
        
        folder_path = Path(folder_input)
        if not folder_path.exists():
            print(f"ERROR: Folder not found: {folder_path}")
            retry = input("Try again? (y/n): ").strip().lower()
            if retry != 'y':
                return
        else:
            break
    
    # Get available CSV files
    csv_files = get_available_csv_files(folder_path)
    
    if not csv_files:
        print(f"\nERROR: No CSV files found in: {folder_path}")
        return
    
    print(f"\nFound {len(csv_files)} CSV file(s)")
    
    # Let user select files
    selected_files = select_csv_files(csv_files)
    if not selected_files:
        return
    
    print(f"\nSelected {len(selected_files)} file(s) for analysis")
    
    # Choose analysis mode
    print("\nAnalysis mode:")
    print("  1. Per-file analysis only")
    print("  2. Overall analysis only (all files combined)")
    print("  3. Both per-file and overall")
    
    while True:
        mode_choice = input("\nSelect analysis mode (1-3): ").strip()
        if mode_choice in ['1', '2', '3']:
            break
        print("ERROR: Invalid choice. Please select 1-3")
    
    # Let user select metrics and statistics
    selected_metrics, selected_stats, include_combined = select_metrics_and_stats()
    
    # Calculate global statistics for normalization
    global_stats = calculate_global_stats(selected_files)
    
    # Perform analysis
    results_list = []
    
    if mode_choice in ['1', '3']:
        print("\nAnalyzing individual files...")
        for csv_file in selected_files:
            print(f"  Processing: {csv_file.name}")
            result = analyze_single_file(csv_file, global_stats, selected_metrics, selected_stats, include_combined)
            if result:
                results_list.append(result)
    
    if mode_choice in ['2', '3']:
        overall_result = analyze_overall(selected_files, global_stats, selected_metrics, selected_stats, include_combined)
        if overall_result:
            results_list.append(overall_result)
    
    if not results_list:
        print("\nERROR: No results generated")
        return
    
    # Display summary
    display_summary(results_list, selected_metrics, selected_stats, include_combined)
    
    # Save to CSV
    print("\n" + "=" * 100)
    while True:
        output_name = input("\nEnter output report name (without extension): ").strip().strip('"').strip("'")
        if output_name:
            break
        print("ERROR: Please provide a valid filename")
    
    output_file = Path(folder_path) / f"{output_name}.csv"
    
    if save_results_to_csv(results_list, output_file):
        # Offer to convert to Excel
        convert = input("\nConvert report to Excel format? (y/n): ").strip().lower()
        if convert == 'y':
            excel_file = output_file.with_suffix('.xlsx')
            csv_excel_converter.csv_to_excel(str(output_file), str(excel_file))
        
        # Offer general CSV/Excel conversion
        more_convert = input("\nOpen CSV ↔ Excel converter for other files? (y/n): ").strip().lower()
        if more_convert == 'y':
            csv_excel_converter.interactive_convert()
    
    print("\n" + "=" * 100)
    print("ANALYSIS COMPLETE")
    print("=" * 100)

if __name__ == "__main__":
    main()

